{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "from torch import nn, optim\r\n",
    "from torch.autograd import Variable\r\n",
    "from torchvision import datasets, transforms\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "print(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "batch_size = 100\r\n",
    "epochs = 20\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_dataset = datasets.MNIST(root='./data', \r\n",
    "                            train=True, \r\n",
    "                            transform=transforms.ToTensor(),\r\n",
    "                            download=True)\r\n",
    "\r\n",
    "test_dataset = datasets.MNIST(root='./data', \r\n",
    "                           train=False, \r\n",
    "                           transform=transforms.ToTensor())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "train_loader = torch.utils.data.DataLoader(\r\n",
    "    dataset=train_dataset, batch_size=batch_size, shuffle=True\r\n",
    ")\r\n",
    "\r\n",
    "# valid_loader = torch.utils.data.DataLoader(\r\n",
    "#     dataset=valid_dataset, batch_size=batch_size, shuffle=False\r\n",
    "# )\r\n",
    "\r\n",
    "test_loader = torch.utils.data.DataLoader(\r\n",
    "    dataset=test_dataset, batch_size=batch_size, shuffle=False\r\n",
    ")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# coRNN Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# class coRNNCell(nn.Module):\r\n",
    "#     def __init__(self, input_size, hidden_size, dt, gamma, epsilon):\r\n",
    "#         super().__init__()\r\n",
    "#         self.dt = dt\r\n",
    "#         self.gamma = gamma\r\n",
    "#         self.epsilon = epsilon\r\n",
    "#         self.i2h = nn.Linear(input_size + hidden_size + hidden_size, hidden_size)\r\n",
    "\r\n",
    "#     def forward(self, x, hy, hz):\r\n",
    "#         combined_layer = torch.cat((x, hz, hy), 1)\r\n",
    "#         hz = hz + self.dt * (\r\n",
    "#             torch.tanh(self.i2h(combined_layer)) - self.gamma * hy - self.epsilon * hz\r\n",
    "#         )\r\n",
    "#         hy = hy + self.dt * hz\r\n",
    "# \r\n",
    "#         return hy, hz\r\n",
    "\r\n",
    "\r\n",
    "# class coRNN(nn.Module):\r\n",
    "#     def __init__(self, input_size, hidden_size, output_size, dt, gamma, epsilon):\r\n",
    "#         super().__init__()\r\n",
    "#         self.hidden_size = hidden_size\r\n",
    "#         self.cell = coRNNCell(input_size, hidden_size, dt, gamma, epsilon)\r\n",
    "#         self.readout = nn.Linear(hidden_size, output_size)\r\n",
    "\r\n",
    "#     def forward():\r\n",
    "#         hy = Variable(torch.zeros(batch_size, hidden_size))\r\n",
    "#         hz = Variable\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Vanilla LSTM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class LSTMModel(nn.Module):\r\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        # ? Hidden layer dimentions\r\n",
    "        self.hidden_size = hidden_size\r\n",
    "\r\n",
    "        self.num_layers = num_layers\r\n",
    "\r\n",
    "        # ? shape: (batch, seq, feature)\r\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\r\n",
    "\r\n",
    "        # ? Readout layer\r\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        # ? x shape: (batch_size, seq_len, input_size)\r\n",
    "        # ? h_0 shape: (num_layers, batch_size, hidden_size)\r\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device))\r\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device))\r\n",
    "\r\n",
    "        # ? out shape: (seq_len, batch_size, hidden_size) => (64, 28, 100)\r\n",
    "        # ? h_n shape: (num_layers * num_directions, batch_size, hidden_size)\r\n",
    "        out, (h_n, c_n) = self.lstm(x, (h_0, c_0))\r\n",
    "\r\n",
    "        out = self.fc(out[:, -1, :])\r\n",
    "\r\n",
    "        return out\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "input_size = 28\r\n",
    "hidden_size = 100\r\n",
    "output_size = 10\r\n",
    "num_layers = 3\r\n",
    "\r\n",
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers)\r\n",
    "model.to(device)\r\n",
    "\r\n",
    "# for param in model.parameters():\r\n",
    "#     print(type(param), param.size(), param.data.shape)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(28, 100, num_layers=3, batch_first=True)\n",
       "  (fc): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "learning_rate = 0.001\r\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\r\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)  \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "seq_size = 28\r\n",
    "\r\n",
    "iter = 0\r\n",
    "for epoch in range(epochs):\r\n",
    "    for i, (images, labels) in enumerate(train_loader):\r\n",
    "        # * (64, 1, 28, 28) -> (64, 28, 28)\r\n",
    "        images = Variable(images.view(-1, seq_size, input_size).to(device))\r\n",
    "        labels = Variable(labels.to(device))\r\n",
    "\r\n",
    "        # ? Forward pass\r\n",
    "        outputs = model(images)\r\n",
    "        loss = criterion(outputs, labels)\r\n",
    "\r\n",
    "        # ? Backward and optimize\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        iter += 1\r\n",
    "        if iter % 500 == 0:\r\n",
    "            total, correct = 0, 0\r\n",
    "\r\n",
    "            # Iterate through test dataset\r\n",
    "            for images, labels in test_loader:\r\n",
    "                images = Variable(images.view(-1, seq_size, input_size).to(device))\r\n",
    "                labels = Variable(labels.to(device))\r\n",
    "\r\n",
    "                # Forward pass only to get logits/output\r\n",
    "                outputs = model(images)\r\n",
    "                # Get predictions from the maximum value\r\n",
    "                _, predicted = torch.max(outputs.data, 1)\r\n",
    "\r\n",
    "                total += labels.size(0)\r\n",
    "                # Total correct predictions\r\n",
    "                correct += (predicted.cpu() == labels.cpu()).sum()\r\n",
    "\r\n",
    "            accuracy = 100 * correct / total\r\n",
    "            print(f\"Epoch: {epoch + 1}, Iteration: {iter}, Loss: {loss.item():.4f}, Accuracy: {accuracy}\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1, Iteration: 500, Loss: 2.3027, Accuracy: 10.279999732971191\n",
      "Epoch: 2, Iteration: 1000, Loss: 2.3088, Accuracy: 10.279999732971191\n",
      "Epoch: 3, Iteration: 1500, Loss: 2.3018, Accuracy: 10.279999732971191\n",
      "Epoch: 4, Iteration: 2000, Loss: 2.2986, Accuracy: 10.279999732971191\n",
      "Epoch: 5, Iteration: 2500, Loss: 2.3104, Accuracy: 10.279999732971191\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# New"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "train_dataset = datasets.MNIST(\r\n",
    "    root=\"./data\", train=True, transform=transforms.ToTensor(), download=True\r\n",
    ")\r\n",
    "\r\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, transform=transforms.ToTensor())\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "batch_size = 100\r\n",
    "n_iters = 3000\r\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\r\n",
    "num_epochs = int(num_epochs)\r\n",
    "\r\n",
    "train_loader = torch.utils.data.DataLoader(\r\n",
    "    dataset=train_dataset, batch_size=batch_size, shuffle=True\r\n",
    ")\r\n",
    "\r\n",
    "test_loader = torch.utils.data.DataLoader(\r\n",
    "    dataset=test_dataset, batch_size=batch_size, shuffle=False\r\n",
    ")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "class LSTMModel(nn.Module):\r\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\r\n",
    "        super(LSTMModel, self).__init__()\r\n",
    "        # Hidden dimensions\r\n",
    "        self.hidden_dim = hidden_dim\r\n",
    "\r\n",
    "        # Number of hidden layers\r\n",
    "        self.layer_dim = layer_dim\r\n",
    "\r\n",
    "        # Building your LSTM\r\n",
    "        # batch_first=True causes input/output tensors to be of shape\r\n",
    "        # (batch_dim, seq_dim, feature_dim)\r\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\r\n",
    "\r\n",
    "        # Readout layer\r\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        # Initialize hidden state with zeros\r\n",
    "        #######################\r\n",
    "        #  USE GPU FOR MODEL  #\r\n",
    "        #######################\r\n",
    "\r\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device))\r\n",
    "        c0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device))\r\n",
    "\r\n",
    "        # One time step\r\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\r\n",
    "\r\n",
    "        # Index hidden state of last time step\r\n",
    "        # out.size() --> 100, 28, 100\r\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states!\r\n",
    "        out = self.fc(out[:, -1, :])\r\n",
    "        # out.size() --> 100, 10\r\n",
    "        return out\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "input_dim = 28\r\n",
    "hidden_dim = 100\r\n",
    "layer_dim = 3  # ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER\r\n",
    "output_dim = 10\r\n",
    "\r\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\r\n",
    "model.to(device)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(28, 100, num_layers=3, batch_first=True)\n",
       "  (fc): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "criterion = nn.CrossEntropyLoss()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "learning_rate = 0.1\r\n",
    "\r\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Number of steps to unroll\r\n",
    "seq_dim = 28\r\n",
    "\r\n",
    "iter = 0\r\n",
    "for epoch in range(num_epochs):\r\n",
    "    for i, (images, labels) in enumerate(train_loader):\r\n",
    "        # Load images as Variable\r\n",
    "        images = Variable(images.view(-1, seq_dim, input_dim)).to(device)\r\n",
    "        labels = Variable(labels).to(device)\r\n",
    "\r\n",
    "        # Clear gradients w.r.t. parameters\r\n",
    "        optimizer.zero_grad()\r\n",
    "\r\n",
    "        # Forward pass to get output/logits\r\n",
    "        # outputs.size() --> 100, 10\r\n",
    "        outputs = model(images)\r\n",
    "\r\n",
    "        # Calculate Loss: softmax --> cross entropy loss\r\n",
    "        loss = criterion(outputs, labels)\r\n",
    "\r\n",
    "        # Getting gradients w.r.t. parameters\r\n",
    "        loss.backward()\r\n",
    "\r\n",
    "        # Updating parameters\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        iter += 1\r\n",
    "\r\n",
    "        if iter % 500 == 0:\r\n",
    "            # Calculate Accuracy\r\n",
    "            correct = 0\r\n",
    "            total = 0\r\n",
    "            # Iterate through test dataset\r\n",
    "            for images, labels in test_loader:\r\n",
    "                #######################\r\n",
    "                #  USE GPU FOR MODEL  #\r\n",
    "                #######################\r\n",
    "                images = Variable(images.view(-1, seq_dim, input_dim)).to(device)\r\n",
    "\r\n",
    "                # Forward pass only to get logits/output\r\n",
    "                outputs = model(images)\r\n",
    "\r\n",
    "                # Get predictions from the maximum value\r\n",
    "                _, predicted = torch.max(outputs.data, 1)\r\n",
    "\r\n",
    "                # Total number of labels\r\n",
    "                total += labels.size(0)\r\n",
    "\r\n",
    "                # Total correct predictions\r\n",
    "                correct += (predicted.cpu() == labels.cpu()).sum()\r\n",
    "\r\n",
    "            accuracy = 100 * correct / total\r\n",
    "\r\n",
    "            # Print Loss\r\n",
    "            print(\r\n",
    "                \"Iteration: {}. Loss: {}. Accuracy: {}\".format(\r\n",
    "                    iter, loss.item(), accuracy\r\n",
    "                )\r\n",
    "            )\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'input_size' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-0c6756f5dc21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m# * (64, 1, 28, 28) -> (64, 28, 28)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_size' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}